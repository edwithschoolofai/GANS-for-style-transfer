{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiscoGAN\n",
    "\n",
    "GAN 을 통해 교차 영역 관계를 배워봅시다\n",
    "https://www.youtube.com/watch?v=9reHvktowLY\n",
    "\n",
    "![alt text](https://pbs.twimg.com/media/C7NDNRuXgAAfePz.jpg \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](http://www.aimechanic.com/wp-content/uploads/2017/03/PyTorch-DiscoGAN.png \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "교차 영역 관계는 인간에게 친숙합니다\n",
    "- 정장과 구두\n",
    "- 영어-불어 통역\n",
    "\n",
    "기계에게도 친숙할 수 있을까요?\n",
    "조건적 이미지 생성 문제입니다\n",
    "ex1) 하나의 영역으로부터 다른 곳으로 매핑하는 함수를 찾기\n",
    "ex2) 다른 영역의 이미지를 주고 한 영역의 이미지를 생성하기\n",
    "\n",
    "오늘날 대부분의 훈련 접근방식은 인간이나\n",
    "알고리즘에 의해 짝지어진 데이터를 사용합니다\n",
    "\n",
    "라벨 없이 해봅시다 :)\n",
    "여러 경우에 사용될 수 있습니다\n",
    "- 게임\n",
    "- 실시간 피드백 디자인\n",
    "\n",
    "\n",
    "하나의 이미지를 가지고 다른 것의 스타일로 재구성하기 위해서는 무엇이 필요할까요?\n",
    "- 인코더-디코더? 너무 단순합니다 (카메라 필터에 더 가깝습니다) \n",
    "- 2 개의 인코더-디코더? 역호환 스타일 옮김, 하지만 여전히 단순합니다\n",
    "- 적대 환경의 2 개의 인코더-디코더? 맞습니다 :) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#왜 GMM 을 사용할까요?\n",
    "#왜 판별기 대신 그래프를 사용할까요?\n",
    "#slim.repeat 함수를 사용합니다\n",
    "#2개의 참조를 추가합니다\n",
    "\n",
    "\n",
    "#파이썬 2 와 파이썬 3 의 차이를 이어줍니다\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os # 파일 저장용\n",
    "import numpy as np #행렬 연산\n",
    "\n",
    "#데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#머신러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "#생성된 데이터에 대한 가우시안 혼합 모델\n",
    "from data_gmm import GMM_distribution, sample_GMM, plot_GMM\n",
    "#데이터 분석\n",
    "from data_utils import shuffle, iter_data\n",
    "\n",
    "#진행 바\n",
    "from tqdm import tqdm\n",
    "\n",
    "#TF-Slim 는 모델을 정의하고, 훈련하고, 평가하는 텐서플로우의 가벼운 라이브러리입니다. 복잡한 네트워크를 빠르고 간결하게 정의할 수 있게 해줍니다\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# 확률적 분포의 배치를 나타내는 클래스입니다\n",
    "#각 클래스는 분포를 정의하는 파라미터로 초기화 됩니다\n",
    "ds = tf.contrib.distributions\n",
    "\n",
    "#교체된 텐서의 타겟을 계산하는 새로운 그래프를 생성합니다\n",
    "\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#하이퍼파라미터\n",
    "\"\"\" parameters \"\"\"\n",
    "n_epoch = 1000 #epcoh 의 수\n",
    "batch_size  = 64\n",
    "dataset_size = 512\n",
    "input_dim = 2 #데이터와 라벨\n",
    "latent_dim = 2 \n",
    "eps_dim = 2\n",
    "\n",
    "\n",
    "#판별기\n",
    "n_layer_disc = 2\n",
    "n_hidden_disc = 256\n",
    "\n",
    "#생성기 \n",
    "n_layer_gen = 2\n",
    "n_hidden_gen= 256\n",
    "\n",
    "#추론망 (생성기 #2)\n",
    "n_layer_inf = 2\n",
    "n_hidden_inf= 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DiscoGAN 폴더에 결과를 저장합니다\n",
    "\"\"\" Create directory for results \"\"\"\n",
    "result_dir = 'results/DiscoGAN/'\n",
    "directory = result_dir\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://image.slidesharecdn.com/sampleproject-140814212447-phpapp02/95/speaker-recognition-using-gaussian-mixture-model-2-638.jpg?cb=1408051684\n",
    " \"Logo Title Text 1\")\n",
    " \n",
    "가우시안 혼합 모델은 모든 데이터 점들이 일정 숫자의 알 수 없는 파라미터를 가진 가우시안 분포의 혼합으로 생성되었다고 가정하는 하나의 확률론적 모델입니다.\n",
    "\n",
    "![alt text](http://i.imgur.com/GJhzOUy.png \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "- X = n 개의 요소를 가진 데이터 세트\n",
    "- alpha = k 번째 요소의 중량조합\n",
    "- sigma = 가우시안 확률 밀도 함수\n",
    "- mu =  k 번째 요소의 평균\n",
    "- sigma2 = k 번째 요소의 분산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#장난감 데이터 세트로 된 데모입니다\n",
    "#5 개의 요소로 된 GMM\n",
    "#가우시안 혼합 모델은 하나의 확률론적 모델로써\n",
    "#모든 데이터 점들이 일정 수의\n",
    "#파라미터를 알 수 없는 가우시안 분포의 혼합으로\n",
    "#생성되었다고 가정합니다\n",
    "\n",
    "# X 데이터 세트를 생성합니다 (첫 번째 데이터 세트)\n",
    "#input_list 의 모든 요소에 대해 함수를 적용합니다\n",
    "#lambda = 익명 함수 (i.e. 이름이 정해져 있지 않은 함수)\n",
    "#5 개의 요소를 가진 numpy 배열을 생성합니다\n",
    "means = map(lambda x:  np.array(x), [[0, 0],\n",
    "                                     [2, 2],\n",
    "                                     [-1, -1],\n",
    "                                     [1, -1],\n",
    "                                     [-1, 1]])\n",
    "\n",
    "#접근 방법을 리스트로 변환합니다\n",
    "means = list(means)\n",
    "#표준 편차\n",
    "std = 0.1\n",
    "#분산 - eye 는 대각선에 1 이 배치되어있고 나머지는 모두 0 인 2차원 배열인 항등 행렬을 반환합니다.\n",
    "variances = [np.eye(2) * std for _ in means]\n",
    "\n",
    "#단서를 가지기 전 이 수치에 대한\n",
    "#누군가의 예상을 표현할 확률 분포\n",
    "priors = [1.0/len(means) for _ in means]\n",
    "\n",
    "#가우시안 혼합 모델을 생성합니다\n",
    "gaussian_mixture = GMM_distribution(means=means,\n",
    "                                               variances=variances,\n",
    "                                               priors=priors)\n",
    "\n",
    "#GMM 을 사용한 데이터의 샘플\n",
    "dataset = sample_GMM(dataset_size, means, variances, priors, sources=('features', ))\n",
    "\n",
    "#결과를 저장합니다\n",
    "save_path = result_dir + 'X_gmm_data.pdf'\n",
    "#결과를 표시합니다\n",
    "plot_GMM(dataset, save_path)\n",
    "\n",
    "#데이터와 라벨을 저장합니다\n",
    "X_np_data= dataset.data['samples']\n",
    "X_labels = dataset.data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 세트 Z 를 생성합니다 (두 번째 데이터 세트)\n",
    "#2 개의 요소를 가진 GMM. \n",
    "means = map(lambda x:  np.array(x), [[-1, -1],[1, 1]])\n",
    "means = list(means)\n",
    "std = 0.1\n",
    "variances = [np.eye(2) * std for _ in means]\n",
    "\n",
    "priors = [1.0/len(means) for _ in means]\n",
    "\n",
    "gaussian_mixture = GMM_distribution(means=means,\n",
    "                                               variances=variances,\n",
    "                                               priors=priors)\n",
    "dataset = sample_GMM(dataset_size, means, variances, priors, sources=('features', ))\n",
    "save_path = result_dir + 'Z_gmm_data.pdf'\n",
    "plot_GMM(dataset, save_path)\n",
    "\n",
    "Z_np_data= dataset.data['samples']\n",
    "Z_labels = dataset.data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x 와 z 의 샘플\n",
    "X_dataset = X_np_data\n",
    "Z_dataset = Z_np_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://pbs.twimg.com/media/C8QiTe2XcAATDfn.jpg \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](http://i.imgur.com/fkEbXXX.png \"Logo Title Text 1\")\n",
    "단순화된 1 차원 영역에 나타낸 모델입니다. (a) 도메인 A 의 두 모드가 도메인 B 의 두 모드에 매핑되는 이상적인 구조, (b) GAN 모델이 실패한 경우, (c) GAN 에서의 재구성 실패\n",
    "\n",
    "\n",
    "\n",
    "2 쌍의 모델이 하나의 도메인으로부터 다른 것으로 매핑하는 것과 \n",
    "재구성을 위한 반대 과정도 학습합니다. \n",
    "\n",
    "두 개의 모델은 동시에 훈련됩니다.\n",
    "\n",
    "- 총 4 개의 생성기\n",
    "- 2 개의 판별기\n",
    "\n",
    "GAB 두 개의 생성기와\n",
    "GBA 두 개의 생성기는 파라미터를 공유하고, 생성된 이미지인\n",
    "xBA 와 xAB 는 판별기 LDA 와\n",
    "LDB 에 적용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 네트워크 \"\"\"\n",
    "\n",
    "#2 쌍의 모델이 하나의 도메인으로부터 다른 것으로 매핑하는 것과\n",
    "#재구성을 위한 반대 과정도 학습합니다.\n",
    "#두 개의 모델은 동시에 훈련됩니다.\n",
    "#GAB 두 개의 생성기와\n",
    "#GBA 두 개의 생성기는 파라미터를 공유하고, 생성된 이미지인\n",
    "#xBA 와 xAB 는 판별기 LDA 와\n",
    "#LDB 에 적용됩니다.\n",
    "\n",
    "\n",
    "\n",
    "#2 개의 생성기\n",
    "def generative_network(z, input_dim, n_layer, n_hidden, eps_dim):\n",
    "    with tf.variable_scope(\"generative\"):\n",
    "        h = z\n",
    "        #repeat 을 사용해 동일한 연산을 반복적으로 실행합니다.\n",
    "        #다수의 완전 연결 층\n",
    "        h = slim.repeat(h, n_layer, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        x = slim.fully_connected(h, input_dim, activation_fn=None, scope=\"p_x\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def inference_network(x, latent_dim, n_layer, n_hidden, eps_dim):\n",
    "    with tf.variable_scope(\"inference\"):\n",
    "        h = x\n",
    "        h = slim.repeat(h, n_layer, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        z = slim.fully_connected(h, latent_dim, activation_fn=None, scope=\"q_z\")\n",
    "    return z\n",
    "\n",
    "\n",
    "#2 개의 판별기\n",
    "def data_network_x(x, n_layers=2, n_hidden=256, activation_fn=None):\n",
    "    \"\"\"Approximate x log data density.\"\"\"\n",
    "    h = tf.concat(x, 1)\n",
    "    with tf.variable_scope('discriminator_x'):\n",
    "        h = slim.repeat(h, n_layers, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        log_d = slim.fully_connected(h, 1, activation_fn=activation_fn)\n",
    "    return tf.squeeze(log_d, squeeze_dims=[1]) #텐서의 모양으로부터\n",
    "    #크기 1 의 차원을 제거합니다.\n",
    "\n",
    "\n",
    "\n",
    "def data_network_z(z, n_layers=2, n_hidden=256, activation_fn=None):\n",
    "    \"\"\"Approximate z log data density.\"\"\"\n",
    "    h = tf.concat(z, 1)\n",
    "    with tf.variable_scope('discriminator_z'):\n",
    "        h = slim.repeat(h, n_layers, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        log_d = slim.fully_connected(h, 1, activation_fn=activation_fn)\n",
    "    return tf.squeeze(log_d, squeeze_dims=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Copying op: concat\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_1/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_1/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_1/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_2/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_2/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_2/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/fully_connected/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/fully_connected/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: Squeeze\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Finalizing op: concat\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_1/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_1/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_1/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_2/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_2/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_2/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/fully_connected/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/fully_connected/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: Squeeze\n",
      "INFO:tensorflow:Copying op: concat_2\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_1/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_1/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_1/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_2/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_2/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_2/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/fully_connected/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/fully_connected/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: Squeeze_2\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Finalizing op: concat_2\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_1/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_1/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_1/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_2/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_2/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_2/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/fully_connected/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/fully_connected/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: Squeeze_2\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Construct model and training ops \"\"\"\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#데이터 1 의 입력\n",
    "x = tf.placeholder(tf.float32, shape=(batch_size, input_dim))\n",
    "#데이터 2 의 입력\n",
    "z = tf.placeholder(tf.float32, shape=(batch_size, latent_dim))\n",
    "\n",
    "# 2 개의 생성기 - 인코더\n",
    "p_x = generative_network(z, input_dim , n_layer_gen, n_hidden_gen, eps_dim)\n",
    "q_z = inference_network(x, latent_dim, n_layer_inf, n_hidden_inf, eps_dim)\n",
    "\n",
    "#로지트 함수는 시그모이드 로지스틱 함수의 역함수입니다\n",
    "\n",
    "#2 개의 판별기\n",
    "decoder_logit_x = data_network_x(p_x, n_layers=n_layer_disc, n_hidden=n_hidden_disc)\n",
    "encoder_logit_x = graph_replace(decoder_logit_x, {p_x: x})\n",
    "\n",
    "decoder_logit_z = data_network_z(q_z, n_layers=n_layer_disc, n_hidden=n_hidden_disc)\n",
    "encoder_logit_z = graph_replace(decoder_logit_z, {q_z: z})\n",
    "\n",
    "#소프트플러스를 계산합니다: log(exp(특성) + 1)\n",
    "#손실 계산을 위한 활성값\n",
    "encoder_sigmoid_x = tf.nn.softplus(encoder_logit_x)\n",
    "decoder_sigmoid_x = tf.nn.softplus(decoder_logit_x)\n",
    "encoder_sigmoid_z = tf.nn.softplus(encoder_logit_z)\n",
    "decoder_sigmoid_z = tf.nn.softplus(decoder_logit_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실 함수\n",
    "\n",
    "#양 판별기의 손실\n",
    "decoder_loss = decoder_sigmoid_x + decoder_sigmoid_z\n",
    "encoder_loss = encoder_sigmoid_x + encoder_sigmoid_z\n",
    "\n",
    "#판별기들의 손실 조합\n",
    "disc_loss = tf.reduce_mean(  encoder_loss ) - tf.reduce_mean( decoder_loss)\n",
    "\n",
    "#2 개의 생성기 (디코더)\n",
    "rec_z = inference_network(p_x, latent_dim, n_layer_inf, n_hidden_inf, eps_dim )\n",
    "rec_x = generative_network(q_z, input_dim , n_layer_gen, n_hidden_gen,  eps_dim )\n",
    "\n",
    "#생성기의 손실을 계산합니다\n",
    "#오류 제곱합의 손실\n",
    "cost_z = tf.reduce_mean(tf.pow(rec_z - z, 2))\n",
    "cost_x = tf.reduce_mean(tf.pow(rec_x - x, 2))\n",
    "#판별기의 손실과 생성기의 손실을 결합합니다\n",
    "adv_loss = tf.reduce_mean(  decoder_loss ) \n",
    "gen_loss = 1*adv_loss + 1.*cost_x  + 1.*cost_z\n",
    "\n",
    "#이름 중 아래를 포함한 변수를 찾습니다\n",
    "qvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"inference\")\n",
    "pvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generative\")\n",
    "dvars_x = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator_x\")\n",
    "dvars_z = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator_z\")\n",
    "\n",
    "#adam (경사 하강법) 을 사용해 최적화합니다\n",
    "opt = tf.train.AdamOptimizer(1e-4, beta1=0.5)\n",
    "\n",
    "#생성기의 손실을 최소화합니다\n",
    "train_gen_op =  opt.minimize(gen_loss, var_list=qvars + pvars)\n",
    "\n",
    "#판별기의 손실을 최소화합니다\n",
    "train_disc_op = opt.minimize(disc_loss, var_list=dvars_x + dvars_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 187/1000 [00:50<03:22,  4.02it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-386464d92975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mf_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_disc_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mzmb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mf_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_z\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mzmb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sraval/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sraval/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sraval/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sraval/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sraval/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" training \"\"\"\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "FG = []\n",
    "FD = []\n",
    "\n",
    "#각 epoch (상태 바의 로그 기록) 마다 반복\n",
    "for epoch in tqdm( range(n_epoch), total=n_epoch):\n",
    "    #양 데이터 세트의 샘플\n",
    "    X_dataset, Z_dataset= shuffle(X_dataset, Z_dataset)\n",
    "\n",
    "    #데이터의 각 x 와 y 에 대해 반복\n",
    "    for xmb, zmb in iter_data(X_dataset, Z_dataset, size=batch_size):\n",
    "        \n",
    "        #손실 함수를 최소화합니다\n",
    "        for _ in range(1):\n",
    "            f_d, _ = sess.run([disc_loss, train_disc_op], feed_dict={x: xmb, z:zmb})\n",
    "        for _ in range(5):\n",
    "            #생성기의 손실을 만드는 3 개의 요소\n",
    "            f_g, _ = sess.run([[adv_loss, cost_x, cost_z], train_gen_op], feed_dict={x: xmb, z:zmb})\n",
    "\n",
    "        FG.append(f_g)\n",
    "        FD.append(f_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" plot the results \"\"\"\n",
    "\n",
    "n_viz = 1\n",
    "imz = np.array([]); rmz = np.array([]); imx = np.array([]); rmx = np.array([]);\n",
    "for _ in range(n_viz):\n",
    "    for xmb, zmb in iter_data(X_np_data, Z_np_data, size=batch_size):\n",
    "        temp_imz = sess.run(q_z, feed_dict={x: xmb, z:zmb})\n",
    "        imz = np.vstack([imz, temp_imz]) if imz.size else temp_imz\n",
    "\n",
    "        temp_rmz = sess.run(rec_z, feed_dict={x: xmb, z:zmb})\n",
    "        rmz = np.vstack([rmz, temp_rmz]) if rmz.size else temp_rmz\n",
    "\n",
    "        temp_imx = sess.run(p_x, feed_dict={x: xmb, z:zmb})\n",
    "        imx = np.vstack([imx, temp_imx]) if imx.size else temp_imx\n",
    "\n",
    "        temp_rmx = sess.run(rec_x, feed_dict={x: xmb, z:zmb})\n",
    "        rmx = np.vstack([rmx, temp_rmx]) if rmx.size else temp_rmx\n",
    "\n",
    "## 추론된 z 의 가장자리값\n",
    "fig_mz, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(X_labels, (n_viz))\n",
    "ax.scatter(imz[:, 0], imz[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "        edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$z_1$'); ax.set_ylabel('$z_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'inferred_mz.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "##  재구성된 z 의 값\n",
    "fig_pz, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(Z_labels, (n_viz))\n",
    "ax.scatter(rmz[:, 0], rmz[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "           edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$z_1$'); ax.set_ylabel('$z_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'reconstruct_mz.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "## 추론된 x 의 가장자리값\n",
    "fig_pz, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(Z_labels, (n_viz))\n",
    "ax.scatter(imx[:, 0], imx[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "        edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$x_1$'); ax.set_ylabel('$x_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'inferred_mx.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "##  재구성된 x 의 값\n",
    "fig_mx, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(X_labels, (n_viz))\n",
    "ax.scatter(rmx[:, 0], rmx[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "           edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$x_1$'); ax.set_ylabel('$x_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'reconstruct_mx.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "## 곡선을 학습합니다\n",
    "fig_curve, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ax.plot(FD, label=\"Discriminator\")\n",
    "ax.plot(np.array(FG)[:,0], label=\"Generator\")\n",
    "ax.plot(np.array(FG)[:,1], label=\"Reconstruction x\")\n",
    "ax.plot(np.array(FG)[:,2], label=\"Reconstruction Z\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.xlabel('Loss')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'learning_curves.pdf', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
